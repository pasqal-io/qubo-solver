{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets \n",
    "\n",
    "We create datasets for different sizes and save them in data/raw_datasets folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from qubosolver import QUBODataset\n",
    "from qubosolver.saveload import save_qubo_dataset, load_qubo_dataset\n",
    "\n",
    "output_directory = Path(str(os.path.abspath(\"01-dataset-generation-and-loading\")).replace(\"docs/tutorial\", \"qubosolver_logs/tutorial\"))\n",
    "dataset_sizes = range(5, 101, 5)\n",
    "instances_per_size = 10\n",
    "densities_list = [0.6]\n",
    "coefficient_bounds = (-100.0, 100.0)\n",
    "seed = 42\n",
    "\n",
    "\n",
    "def create_and_save_dataset(\n",
    "    output_dir: str,\n",
    "    dataset_name: str,\n",
    "    size: int,\n",
    "    num_instances: int,\n",
    "    densities: list[float],\n",
    "    coefficient_bounds: tuple[float, float],\n",
    "    device: str = \"cpu\",\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "    seed: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a QUBODataset with bounds on fixed coefficient and save.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Output directory.\n",
    "        dataset_name (str): File name to generate.\n",
    "        size (int): Dimension of QUBO (size x size).\n",
    "        num_instances (int): Number of instances for each density.\n",
    "        densities (list[float]): List of densities (ratio of non-null elements).\n",
    "        coefficient_bounds (tuple[float, float]): Interval (min, max) of non-null values.\n",
    "        device (str): Device (“cpu” ou “cuda”).\n",
    "        dtype (torch.dtype): Tensor dtype.\n",
    "        seed (int | None): Seed for reproductibility.\n",
    "    \"\"\"\n",
    "    # Génère le dataset\n",
    "    dataset = QUBODataset.from_random(\n",
    "        n_matrices=num_instances,\n",
    "        matrix_dim=size,\n",
    "        densities=densities,\n",
    "        coefficient_bounds=coefficient_bounds,\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir, dataset_name)\n",
    "    save_qubo_dataset(dataset, file_path)\n",
    "    print(f\"Dataset saved to {file_path}\")\n",
    "    \n",
    "## to generate dataset, uncomment the below\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     for size in dataset_sizes:\n",
    "#         fname = f\"raw_qubo_dataset_size_{size}.pt\"\n",
    "#         create_and_save_dataset(\n",
    "#             output_dir=output_directory,\n",
    "#             dataset_name=fname,\n",
    "#             size=size,\n",
    "#             num_instances=instances_per_size,\n",
    "#             densities=densities_list,\n",
    "#             coefficient_bounds=coefficient_bounds,\n",
    "#             device=\"cpu\",\n",
    "#             dtype=torch.float32,\n",
    "#             seed=seed,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets\n",
    "\n",
    "\n",
    "Here we load the datasets and show they can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets_by_size(directory: str):\n",
    "    \"\"\"\n",
    "    Loads datasets from a directory by extracting the size from filenames.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing dataset files.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, torch.Tensor]: A dictionary where keys are sizes and values are loaded datasets.\n",
    "    \"\"\"\n",
    "    # Regular expression to match filenames like \"raw_qubo_dataset_size_{size}.pt\"\n",
    "    pattern = r\"raw_qubo_dataset_size_(\\d+)\\.pt\"\n",
    "    datasets_by_size = {}\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    for filename in os.listdir(directory):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            size = int(match.group(1))\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            dataset = load_qubo_dataset(file_path)\n",
    "            datasets_by_size[size] = dataset\n",
    "            print(f\"Loaded dataset with size {size} from {file_path}\")\n",
    "    return datasets_by_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets is a dict for all qubo datasets for different sizes\n",
    " - datasets[5] = will give us the qubodatasets of size 5 with different densities and different disparities.\n",
    " - the qubo dataset also has the solution component - which is None for all the datasets in the raw_datasets folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_datasets_by_size(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset of a specific size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "data_size_5 = datasets[size]\n",
    "\n",
    "first_qubo_cofficents, first_qubo_solution = data_size_5[9]\n",
    "print(f\"Coefficients : {first_qubo_cofficents}\")\n",
    "print(f\"Solution : {first_qubo_solution}\") # None because raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "for coefficients, solution  in datasets[size]:\n",
    "    print(f\"Size of the qubo {size}\")\n",
    "    print(f\"Coefficients : {coefficients}\")\n",
    "    print(f\"Solution : {solution}\") # None because raw data\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate thorough all sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, dataset in datasets.items():\n",
    "    for coefficients, solution  in dataset:\n",
    "        print(f\"Size of the qubo {size}\")\n",
    "        print(f\"Coefficients : {coefficients}\")\n",
    "        print(f\"Solution : {solution}\") # None because raw data\n",
    "\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubosolver.utils import calculate_density\n",
    "\n",
    "for size, dataset in datasets.items():\n",
    "    for coefficients, solution  in dataset:\n",
    "        print(f\"Size of the qubo {size}\")\n",
    "        print(f\"Coefficients : {coefficients}\")\n",
    "        print(f\"Solution : {solution}\") # None because raw data\n",
    "        print(f\"Density : {calculate_density(coefficients, size)}\") \n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a QUBOInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubosolver import QUBOInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, dataset in datasets.items():\n",
    "    for coefficients, solution  in dataset:\n",
    "        print(f\"Size of the qubo {size}\")\n",
    "        print(f\"Coefficients : {coefficients}\")\n",
    "        print(f\"Solution : {solution}\") # None because raw data\n",
    "        \n",
    "        qubo_inst = QUBOInstance(coefficients)\n",
    "        print(f\"QUBO Instance : {qubo_inst}\")\n",
    "\n",
    "\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a solution\n",
    "\n",
    "We can add solutions using QUBOSOlution class. This solution element is also available in the QUBOInstance, but can also be defined outside.\n",
    "\n",
    "- We can further create a dataset from these solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubosolver.data import QUBOSolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "coff = None\n",
    "solutions = []\n",
    "\n",
    "for i in range(10):\n",
    "    coefficients, _ = datasets[size][i]\n",
    "    # print(f\"Size of the qubo {size}\")\n",
    "    # print(f\"Coefficients : {coefficients}\")\n",
    "    if coff is None:\n",
    "        coff = coefficients.unsqueeze(2)\n",
    "    else:\n",
    "        coff = torch.cat((coff, coefficients.unsqueeze(2)), dim=2)\n",
    "    \n",
    "    qubo_inst = QUBOInstance(coefficients)\n",
    "    print(f\"QUBO Instance : {qubo_inst}\")\n",
    "\n",
    "    # Do your processing \n",
    "    # the solution should be saved in the QUBO Instance\n",
    "    # and can be extracted as\n",
    "    # qubo_solution = qubo_inst.solution\n",
    "    # But here we just define outside, as the solver is not defined yet. \n",
    "    qubo_sol = QUBOSolution(bitstrings=torch.Tensor([[1, 0, 1, 1, 0]]), \n",
    "                            costs=torch.Tensor([0.5]))\n",
    "    solutions.append(qubo_sol)\n",
    "    print(\"Updated Solution : \", qubo_sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = QUBODataset(coefficients=coff, solutions=solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
